{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f740a3a0-7d3a-4c8d-b85d-a2c8d278d097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import yfinance as yf\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime\n",
    "from google.cloud import pubsub_v1, bigquery\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6a2a175-cc53-4081-a9d1-b54425e02519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Google Cloud credentials\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = r\"C:\\\\Stock_pred\\\\stockanalysis-444512-3fd7af0c6e0a.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9851fc68-06bd-4282-8a40-756cfe0d7090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ML model\n",
    "model = load_model('C:\\\\Stock_pred\\\\saved_model\\\\lstm_model.keras')\n",
    "\n",
    "# Initialize BigQuery client\n",
    "bigquery_client = bigquery.Client(project=\"stockanalysis-444512\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ab78b77-8d1e-44b6-8ef1-73c5e8b86f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(stock_data):\n",
    "    \"\"\"Prepare features for ML model prediction.\"\"\"\n",
    "    feature_columns = [\"Open\", \"High\", \"Low\", \"Close\"]\n",
    "    if len(stock_data) < 5:\n",
    "        raise ValueError(\"Not enough data to make a prediction. Requires at least 5 time steps.\")\n",
    "    features = stock_data[feature_columns].tail(5).values\n",
    "    return features.reshape((1, 5, 4))\n",
    "\n",
    "def predict_trend(features):\n",
    "    \"\"\"Predict stock trend using ML model.\"\"\"\n",
    "    prediction = model.predict(features)\n",
    "    return \"up\" if prediction[0] == 1 else \"down\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18c499b1-59d8-45ca-9f85-df122d3e2260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pub/Sub setup\n",
    "project_id = \"stockanalysis-444512\"\n",
    "topic_id = \"real-time-stock-data\"\n",
    "subscription_id = \"real-time-stock-data-sub\"\n",
    "publisher = pubsub_v1.PublisherClient()\n",
    "subscriber = pubsub_v1.SubscriberClient()\n",
    "topic_path = publisher.topic_path(project_id, topic_id)\n",
    "subscription_path = subscriber.subscription_path(project_id, subscription_id)\n",
    "\n",
    "# Publish stock data to Pub/Sub\n",
    "def publish_stock_data(tickers):\n",
    "    for ticker in tickers:\n",
    "        stock_data = yf.download(ticker, interval='5m', period='5d')\n",
    "        if stock_data.empty:\n",
    "            print(f\"No data fetched for {ticker}.\")\n",
    "            continue\n",
    "        latest_row = stock_data.iloc[-1]\n",
    "        stock_message = {\n",
    "            \"symbol\": ticker,\n",
    "            \"price\": round(float(latest_row[\"Close\"].iloc[0]), 2),\n",
    "            \"timestamp\": latest_row.name.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "        }\n",
    "        message = json.dumps(stock_message).encode(\"utf-8\")\n",
    "        future = publisher.publish(topic_path, message)\n",
    "        print(f\"Published message for {ticker} with ID: {future.result()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce9e1b76-862e-4956-9827-7fdffdc7c8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for messages on projects/stockanalysis-444512/subscriptions/real-time-stock-data-sub...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "Prediction for AAPL inserted into BigQuery.\n",
      "Prediction for INTC inserted into BigQuery.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for TSLA inserted into BigQuery.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for AMZN inserted into BigQuery.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for BABA inserted into BigQuery.\n"
     ]
    }
   ],
   "source": [
    "# Subscriber callback\n",
    "def callback(message):\n",
    "    try:\n",
    "        raw_data = message.data.decode(\"utf-8\")\n",
    "        data = json.loads(raw_data)\n",
    "        required_keys = {\"symbol\", \"price\", \"timestamp\"}\n",
    "        if not required_keys.issubset(data.keys()):\n",
    "            print(f\"Missing keys in message: {data}\")\n",
    "            message.nack()\n",
    "            return\n",
    "\n",
    "        # Fetch recent stock data for feature preparation\n",
    "        stock_data = yf.download(data[\"symbol\"], interval='5m', period='5d')\n",
    "        features = prepare_features(stock_data)\n",
    "        predicted_trend = predict_trend(features)\n",
    "\n",
    "        # Insert prediction into BigQuery\n",
    "        table_ref = \"stockanalysis-444512.stock_analysis.stream_mltobq\"\n",
    "        row_to_insert = {\n",
    "            \"symbol\": data[\"symbol\"],\n",
    "            \"price\": data[\"price\"],\n",
    "            \"timestamp\": data[\"timestamp\"],\n",
    "            \"predicted_trend\": predicted_trend\n",
    "        }\n",
    "        errors = bigquery_client.insert_rows_json(table_ref, [row_to_insert])\n",
    "        if errors:\n",
    "            print(f\"BigQuery errors: {errors}\")\n",
    "        else:\n",
    "            print(f\"Prediction for {data['symbol']} inserted into BigQuery.\")\n",
    "\n",
    "        message.ack()\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing message: {e}\")\n",
    "        message.nack()\n",
    "\n",
    "# Start Pub/Sub subscriber\n",
    "subscriber.subscribe(subscription_path, callback=callback)\n",
    "print(f\"Listening for messages on {subscription_path}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9deadb64-2f48-4d00-8428-7a0cda1dee07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data into BigQuery\n",
    "merge_query = \"\"\"\n",
    "MERGE `stockanalysis-444512.stock_analysis.stream_mltobq` T\n",
    "USING (\n",
    "    SELECT symbol, price, timestamp, predicted_trend FROM `stockanalysis-444512.stock_analysis.stream_pubsubtobq`\n",
    "    WHERE NOT EXISTS (\n",
    "        SELECT 1 FROM `stockanalysis-444512.stock_analysis.stream_mltobq` M\n",
    "        WHERE T.symbol = M.symbol AND T.timestamp = M.timestamp\n",
    "    )\n",
    ") S\n",
    "ON T.symbol = S.symbol AND T.timestamp = S.timestamp\n",
    "WHEN NOT MATCHED THEN\n",
    "INSERT (symbol, price, timestamp, predicted_trend)\n",
    "VALUES (S.symbol, S.price, S.timestamp, S.predicted_trend)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553600f7-26a6-44d6-a779-b10d03897991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Published message for TSLA with ID: 13473778826096647\n",
      "Published message for AAPL with ID: 13474321334745635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Published message for MSFT with ID: 13474044197589644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Published message for GOOGL with ID: 13474084363586647\n",
      "Published message for AMZN with ID: 13620395647108117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Published message for ORCL with ID: 13474248550838686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Published message for INTC with ID: 13474196264470193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Published message for NVDA with ID: 13473695341808934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Published message for META with ID: 13474248035957527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Published message for BABA with ID: 13473760417664484\n"
     ]
    }
   ],
   "source": [
    "def run_merge_query():\n",
    "    query_job = bigquery_client.query(merge_query)\n",
    "    query_job.result()\n",
    "    print(\"Data merged successfully.\")\n",
    "\n",
    "# Periodically fetch data, publish, and merge\n",
    "if __name__ == \"__main__\":\n",
    "    tickers = [\"TSLA\", \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"ORCL\", \"INTC\", \"NVDA\", \"META\", \"BABA\"]\n",
    "    publish_stock_data(tickers)\n",
    "    while True:\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7deb6e2-6e3e-4beb-93f9-65e6ad0d408e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
